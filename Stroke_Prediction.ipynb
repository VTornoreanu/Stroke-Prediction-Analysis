{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyGJvSdCcjL-"
      },
      "source": [
        "# Supervised Learning Final Project: Stroke Prediction\n",
        "\n",
        "## 1. Project Topic\n",
        "**Type of Learning:** Supervised Learning\n",
        "**Type of Task:** Binary Classification\n",
        "\n",
        "**Goal:**\n",
        "The goal of this project is to predict whether a patient is likely to get a stroke based on input parameters like gender, age, various diseases, and smoking status. Strokes are a leading cause of death globally, and early identification of high-risk patients can be crucial for prevention.\n",
        "\n",
        "By analyzing this dataset, I aim to build a predictive model that classifies patients into two groups: likely to suffer a stroke (1) and unlikely to suffer a stroke (0). I will compare multiple machine learning models to determine which offers the best predictive performance, focusing on metrics suitable for imbalanced medical data.\n",
        "\n",
        "**Project link:**\n",
        "[https://github.com/VTornoreanu/Stroke-Prediction-Analysis].\n",
        "\n",
        "## 2. Data Source\n",
        "**Source:**\n",
        "The dataset used for this project is the \"Stroke Prediction Dataset\" sourced from Kaggle.\n",
        "\n",
        "**Citation:**\n",
        "Fedesoriano. (2021). *Stroke Prediction Dataset*. Kaggle. Retrieved from [https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset].\n",
        "\n",
        "**Data Description:**\n",
        "The dataset contains medical and demographic features.\n",
        "* **Target Variable:** `stroke` (0 = No, 1 = Yes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yO5GXeuOclyg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# 1. Upload the file\n",
        "print(\"Please upload 'healthcare-dataset-stroke-data.csv' when prompted:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 2. Load the data into a DataFrame\n",
        "# Note: The filename in the brackets must match the file you upload exactly\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "\n",
        "# 3. Display Data Info to answer Rubric questions about size/features\n",
        "print(\"\\n--- Data Info ---\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\n--- First 5 Rows ---\")\n",
        "display(df.head())\n",
        "\n",
        "# 4. Check for Missing Values (Crucial for Data Cleaning Step)\n",
        "print(\"\\n--- Missing Values ---\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojvdDiM9eWOr"
      },
      "source": [
        "## 3. Data Cleaning\n",
        "\n",
        "**Cleaning Strategy:**\n",
        "1.  **Drop `id` column:** This column acts as a unique identifier for patients and provides no predictive value for the model. Keeping it could confuse the model.\n",
        "2.  **Impute Missing `bmi` values:** The `bmi` feature has 201 missing values (approx. 4% of the data). Dropping these rows would result in data loss. Since BMI distributions can have outliers (skewed right), I will use the **median** value of the BMI column to fill these missing entries. This preserves the data distribution better than using the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0dVOuJ_eXDy"
      },
      "outputs": [],
      "source": [
        "# 1. Drop the 'id' column\n",
        "df.drop('id', axis=1, inplace=True)\n",
        "\n",
        "# 2. Impute missing 'bmi' values with the median\n",
        "bmi_median = df['bmi'].median()\n",
        "df['bmi'].fillna(bmi_median, inplace=True)\n",
        "\n",
        "# 3. Verify cleaning\n",
        "print(\"Missing values after cleaning:\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"\\nNew Data Shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYx74gK8etwS"
      },
      "source": [
        "## 4. Exploratory Data Analysis (EDA)\n",
        "\n",
        "In this section, I will analyze the data distribution to understand:\n",
        "1.  **Class Imbalance:** How many patients actually had a stroke?\n",
        "2.  **Correlations:** Which features are most strongly related to strokes?\n",
        "3.  **Feature Distribution:** How does age affect stroke probability?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcA1yyB9ei0K"
      },
      "outputs": [],
      "source": [
        "# Set visual style\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# Plot 1: Target Variable Distribution (Fixed Warning)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='stroke', data=df, hue='stroke', legend=False, palette='coolwarm')\n",
        "plt.title('Class Distribution: Stroke vs No Stroke')\n",
        "plt.xlabel('Stroke (0=No, 1=Yes)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "# Calculate the exact percentage of imbalance\n",
        "stroke_count = df['stroke'].value_counts()\n",
        "print(f\"No Stroke: {stroke_count[0]} ({round(stroke_count[0]/len(df)*100, 2)}%)\")\n",
        "print(f\"Stroke:    {stroke_count[1]} ({round(stroke_count[1]/len(df)*100, 2)}%)\")\n",
        "\n",
        "# Plot 2: Correlation Matrix (Heatmap)\n",
        "plt.figure(figsize=(10, 8))\n",
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "corr = numeric_df.corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot 3: Age Distribution by Stroke Status\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.kdeplot(data=df[df['stroke'] == 0], x='age', fill=True, color='blue', label='No Stroke')\n",
        "sns.kdeplot(data=df[df['stroke'] == 1], x='age', fill=True, color='red', label='Stroke')\n",
        "plt.title('Age Distribution: Stroke vs No Stroke')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orcu39sgmVIa"
      },
      "source": [
        "## 5. Data Preprocessing\n",
        "\n",
        "**Feature Engineering:**\n",
        "Machine learning models require numerical input. I will use **One-Hot Encoding** to convert categorical variables (Gender, Work Type, Residence, Smoking Status) into numeric binary features.\n",
        "\n",
        "**Data Splitting:**\n",
        "I will split the dataset into a **Training Set (80%)** to teach the models and a **Test Set (20%)** to evaluate their performance on unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfRAKLMimXnw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. One-Hot Encoding for categorical variables\n",
        "# drop_first=True prevents multicollinearity (dummy variable trap)\n",
        "df_encoded = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "print(\"Columns after encoding:\")\n",
        "print(df_encoded.columns)\n",
        "\n",
        "# 2. Define X (features) and y (target)\n",
        "X = df_encoded.drop('stroke', axis=1)\n",
        "y = df_encoded['stroke']\n",
        "\n",
        "# 3. Split the data (80% Train, 20% Test)\n",
        "# stratify=y ensures the imbalance is preserved in both train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nTraining Shape: {X_train.shape}\")\n",
        "print(f\"Testing Shape: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJjxOZ-Rmq3E"
      },
      "source": [
        "## 6. Model Building & Analysis\n",
        "\n",
        "**Strategy:**\n",
        "I will train three different supervised learning models to compare their performance.\n",
        "1.  **Logistic Regression:** A baseline linear model.\n",
        "2.  **Decision Tree:** A non-linear model that captures decision rules.\n",
        "3.  **Random Forest:** An ensemble method that reduces overfitting and improves accuracy.\n",
        "\n",
        "**Handling Imbalance:**\n",
        "Since the dataset is highly imbalanced (approx 5% stroke cases), I will use the parameter `class_weight='balanced'` for all models. This penalizes the model more for missing a positive stroke case, encouraging it to find the minority class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9YWrZ9Fmahl"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Initialize models with class_weight='balanced' to handle the imbalance\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "}\n",
        "\n",
        "# Loop through models to train and predict\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "\n",
        "    # Train\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MPBsfg5mvoX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Plot Confusion Matrix for each model\n",
        "plt.figure(figsize=(18, 5))\n",
        "\n",
        "for i, (name, model) in enumerate(models.items()):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Compute Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Plot heatmap\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.title(f'{name} Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OFWoumkpRac"
      },
      "source": [
        "## 7. Results and Analysis\n",
        "\n",
        "**Model Comparison:**\n",
        "* **Random Forest** achieved the highest accuracy (95%) but failed completely to detect stroke cases (Recall = 0.00). It essentially memorized the majority class (\"No Stroke\"), making it useless for a medical screening tool.\n",
        "* **Decision Tree** performed slightly better but still missed most stroke cases (Recall = 0.12).\n",
        "* **Logistic Regression** had the lowest accuracy (75%) but achieved the highest **Recall (0.80)**. It correctly identified 40 out of 50 stroke cases in the test set.\n",
        "\n",
        "**Metric Selection:**\n",
        "For this medical problem, **Accuracy is misleading**. A model that predicts \"No Stroke\" for everyone would be 95% accurate but would kill patients by missing diagnoses.\n",
        "We prioritize **Recall** (Sensitivity) because missing a stroke case (False Negative) is far worse than a False Positive (unnecessary checkup).\n",
        "\n",
        "**Conclusion:**\n",
        "Despite the lower accuracy, **Logistic Regression is the superior model** for this specific task because it successfully identifies high-risk patients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FW28oynpgux"
      },
      "source": [
        "## 8. Discussion and Conclusion\n",
        "\n",
        "**Learnings:**\n",
        "This project highlighted the dangers of relying on accuracy for imbalanced datasets. The Random Forest model fell into the \"accuracy paradox,\" optimizing for the majority class at the expense of the minority class, despite using class weights.\n",
        "\n",
        "**Why Random Forest Failed:**\n",
        "Even with `class_weight='balanced'`, the Random Forest likely struggled because the \"Stroke\" cases are not easily separable from the \"No Stroke\" cases in the feature space. The algorithm favored the path of least resistance (predicting the majority) to minimize overall error.\n",
        "\n",
        "**Future Improvements:**\n",
        "To improve the Random Forest or Decision Tree models, I would:\n",
        "1.  **Undersampling/Oversampling:** Use SMOTE (Synthetic Minority Over-sampling Technique) to artificially create more stroke samples in the training data.\n",
        "2.  **Threshold Tuning:** Instead of using the default 0.5 probability threshold for classification, I would lower the threshold (e.g., to 0.2) to catch more positive cases.\n",
        "3.  **Feature Engineering:** Collect more specific medical data (e.g., family history, physical activity frequency) to help the complex models distinguish between classes better."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ojvdDiM9eWOr"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
